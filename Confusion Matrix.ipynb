{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Confusion Matrix.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"IE7JD0d-nuYE","colab_type":"text"},"source":["##Describing the predictive performance of a model using confusion matrix\n","In the last [tutorial](https://github.com/Xujan24/Machine-Learning/blob/master/Titanic%20Classification%20Challenge.ipynb), we created a logistic regression model and described it's performance using **AUC-ROC** curve. In this tutorial, we will be using another technique, known as **Confusion Matrix**, to describe the predictive performance of a trained model. A confusion matrix presents the performance of a classification model in a tabular form.\n","\n","The dataset we will be working on, in this tutorial, is a breast cancer wisconsin dataset. The dataset has 30 numeric input features and 2 output classes, i.e. Malignant and Benign. The features were computed from a digitized image of a fine needle aspirate (FAN) of a breast mass.  You can view more details of the dataset and related papers, from [this](https://goo.gl/U2Uwz2) link. You can also download a copy of the dataset for the same link. However, the dataset is provided within the `sklearn` package. For a complete list of the provided dataset and thier usage, please consult [this](https://scikit-learn.org/stable/datasets/index.html) link.\n","\n","In this tutorial, we will be using an ensemble technique, called Gradient Tree Boosting or Gradient Boosted Regression Trees, as our reference model. Boosting is a family of machine learning algorithms that builds a strong prediction model by grouping weaker models.  The Gradient Tree Boosting technique uses decision trees as the base (or weak) learners and produces a powerful prediction model in the form of an ensemble of these base learners. For more details about boosting and gradient boosted trees, you can go through [this](https://en.wikipedia.org/wiki/Gradient_boosting) wikipedia page.\n","\n","### Import Dataset\n","First thing first, let's import the breast cancer wisconsin dataset."]},{"cell_type":"code","metadata":{"id":"yelqNJIkWNYs","colab_type":"code","colab":{}},"source":["from sklearn import datasets;\n","\n","cancerDataset = datasets.load_breast_cancer();\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c2tWEnUs2dp4","colab_type":"text"},"source":["The `load_breast_cancer()`function returns a Bunch object by default. If you want a tuple insted, you can set the `return_X_y` flag to `true`.  A bunch is a subclass of `dict` and lets us to use it as an object. For example, we can get the input features from the above bunch object as below:"]},{"cell_type":"code","metadata":{"id":"TNvvpWU1W70w","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":156},"outputId":"eb679678-5c29-4b77-8a09-93491dcbce2b","executionInfo":{"status":"ok","timestamp":1557108054838,"user_tz":-600,"elapsed":875,"user":{"displayName":"Santosh Purja Pun","photoUrl":"https://lh3.googleusercontent.com/-lSFl4QnIVIk/AAAAAAAAAAI/AAAAAAAAAIY/zqCf6YZz0-4/s64/photo.jpg","userId":"11631572469968879053"}}},"source":["# input features\n","print(cancerDataset.data)\n","\n","# shape of input features\n","print(cancerDataset.data.shape)"],"execution_count":86,"outputs":[{"output_type":"stream","text":["[[1.799e+01 1.038e+01 1.228e+02 ... 2.654e-01 4.601e-01 1.189e-01]\n"," [2.057e+01 1.777e+01 1.329e+02 ... 1.860e-01 2.750e-01 8.902e-02]\n"," [1.969e+01 2.125e+01 1.300e+02 ... 2.430e-01 3.613e-01 8.758e-02]\n"," ...\n"," [1.660e+01 2.808e+01 1.083e+02 ... 1.418e-01 2.218e-01 7.820e-02]\n"," [2.060e+01 2.933e+01 1.401e+02 ... 2.650e-01 4.087e-01 1.240e-01]\n"," [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 2.871e-01 7.039e-02]]\n","(569, 30)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"P2xwQWtQ33mO","colab_type":"text"},"source":["To view a complete list of keys in the above bunch object, we can simply call `.keys()` method."]},{"cell_type":"code","metadata":{"id":"DlUt1R4C4B0Z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"39fed292-a53a-4113-a8ae-d06fedb6c9f5","executionInfo":{"status":"ok","timestamp":1557108130397,"user_tz":-600,"elapsed":880,"user":{"displayName":"Santosh Purja Pun","photoUrl":"https://lh3.googleusercontent.com/-lSFl4QnIVIk/AAAAAAAAAAI/AAAAAAAAAIY/zqCf6YZz0-4/s64/photo.jpg","userId":"11631572469968879053"}}},"source":["print(cancerDataset.keys())"],"execution_count":87,"outputs":[{"output_type":"stream","text":["dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"D3gaBiK54Ot7","colab_type":"text"},"source":["The above bunch object has 6 keys of which, data is for the input features, target is the corresponding output classes and target_names contains information about the actual classes. The rest are just metadata - description about the dataset.\n","\n","Let's store our input features, output classes and the class labels into separate variables."]},{"cell_type":"code","metadata":{"id":"wB0RAC9FbGgg","colab_type":"code","colab":{}},"source":["# storing input features and output classes into X and y variables respectively;\n","X, y = cancerDataset.data, cancerDataset.target\n","\n","# storing the output class label\n","classLabels = cancerDataset.target_names"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A0Udbh5g5wyW","colab_type":"text"},"source":["###Split data into training and test set\n","Next, we split the dataset into training and test set. We will be using 30% of the total dataset for test purpose."]},{"cell_type":"code","metadata":{"id":"mx89gWCxbu33","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split;\n","train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = 0.3, random_state = 123, shuffle = True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rqtTxvIj6DTN","colab_type":"text"},"source":["###Build Model\n","As discuissed earlier, we will be using Gradient Tree Boosting as our base classifier. So let's create our classifier and train it using the training dataset."]},{"cell_type":"code","metadata":{"id":"CsS6OKhzcgPm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":173},"outputId":"2b766671-4e3b-4832-e92f-94f4fc8f082c","executionInfo":{"status":"ok","timestamp":1557109589908,"user_tz":-600,"elapsed":846,"user":{"displayName":"Santosh Purja Pun","photoUrl":"https://lh3.googleusercontent.com/-lSFl4QnIVIk/AAAAAAAAAAI/AAAAAAAAAIY/zqCf6YZz0-4/s64/photo.jpg","userId":"11631572469968879053"}}},"source":["from sklearn.ensemble import GradientBoostingClassifier\n","\n","model = GradientBoostingClassifier(n_estimators = 100, learning_rate = 1.0, max_depth = 1, random_state = 123);\n","model.fit(train_X, train_y)"],"execution_count":106,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GradientBoostingClassifier(criterion='friedman_mse', init=None,\n","              learning_rate=1.0, loss='deviance', max_depth=1,\n","              max_features=None, max_leaf_nodes=None,\n","              min_impurity_decrease=0.0, min_impurity_split=None,\n","              min_samples_leaf=1, min_samples_split=2,\n","              min_weight_fraction_leaf=0.0, n_estimators=100,\n","              n_iter_no_change=None, presort='auto', random_state=123,\n","              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n","              verbose=0, warm_start=False)"]},"metadata":{"tags":[]},"execution_count":106}]},{"cell_type":"markdown","metadata":{"id":"N4aiGwH-6W0i","colab_type":"text"},"source":["###Model Evaluation\n","Once we have our trained model, the next thing is to evaluate our model performance using the test set."]},{"cell_type":"code","metadata":{"id":"NRFQk3xw7da6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"e80540c3-b0e0-4f55-9e1b-cd1d7038ceb2","executionInfo":{"status":"ok","timestamp":1557109596911,"user_tz":-600,"elapsed":762,"user":{"displayName":"Santosh Purja Pun","photoUrl":"https://lh3.googleusercontent.com/-lSFl4QnIVIk/AAAAAAAAAAI/AAAAAAAAAIY/zqCf6YZz0-4/s64/photo.jpg","userId":"11631572469968879053"}}},"source":["print(\"Model accuracy: %f%%\" % round((model.score(test_X, test_y)*100), 2))"],"execution_count":107,"outputs":[{"output_type":"stream","text":["Model accuracy: 97.660000%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2CoyA5xVN-tZ","colab_type":"text"},"source":["So, the accuracy of our model is 97.66%, which is not bad. Now, the next thing we will be doing is describe the performance of our model using a confusion matrix."]},{"cell_type":"markdown","metadata":{"id":"1QIv31438tMW","colab_type":"text"},"source":["###Confusion Matrix\n","To create a confusion matrix we need to have the values predicted by our model for each of the samples in the test set."]},{"cell_type":"code","metadata":{"id":"6GfC9HpC9mgM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":104},"outputId":"c02b3167-5310-4292-d022-4ee658d47324","executionInfo":{"status":"ok","timestamp":1557109609466,"user_tz":-600,"elapsed":859,"user":{"displayName":"Santosh Purja Pun","photoUrl":"https://lh3.googleusercontent.com/-lSFl4QnIVIk/AAAAAAAAAAI/AAAAAAAAAIY/zqCf6YZz0-4/s64/photo.jpg","userId":"11631572469968879053"}}},"source":["pred_y = model.predict(test_X)\n","print(pred_y)"],"execution_count":108,"outputs":[{"output_type":"stream","text":["[1 1 0 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 1 1 1 0 1 1\n"," 1 1 0 0 1 0 1 0 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 1 1 1 1 0 1 1 1 0 1 1 1 1\n"," 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 0 0 0 1 0 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 0 1 0 1 0 1 0 0\n"," 1 0 1 0 1 1 0 1 0 0 0 1 1 1 0 0 1 1 1 0 0 0 0]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vZxuqo5G9zFs","colab_type":"text"},"source":["Now, let's calculate the confusion matrix. The `sklearn` package has built-in support for this task. To use it we need to import `confusion_matrix` from `sklearn.metrics`. For a complete list of available metrics for both classification and regression, please go through [this](https://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics) link."]},{"cell_type":"code","metadata":{"id":"PSjVC_0YdMrf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"6c492dc4-e431-4d47-ef46-7d9f1bb7fca8","executionInfo":{"status":"ok","timestamp":1557101345810,"user_tz":-600,"elapsed":1416,"user":{"displayName":"Santosh Purja Pun","photoUrl":"https://lh3.googleusercontent.com/-lSFl4QnIVIk/AAAAAAAAAAI/AAAAAAAAAIY/zqCf6YZz0-4/s64/photo.jpg","userId":"11631572469968879053"}}},"source":["from sklearn.metrics import confusion_matrix;\n","\n","cm = confusion_matrix(test_y, pred_y);\n","print(cm)"],"execution_count":46,"outputs":[{"output_type":"stream","text":["[[ 66   2]\n"," [  2 101]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hT-ZCjaq-pvu","colab_type":"text"},"source":["Okay we have calculated the confusion matrix for our model and what we got is just a list of list containing numbers. This might not be so much meaningful itself. Let's make it meaningful and easy to interprete."]},{"cell_type":"code","metadata":{"id":"ZBhzSu12ePXj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":295},"outputId":"708cad26-1242-4a13-a603-3cc6b3127535","executionInfo":{"status":"ok","timestamp":1557110131423,"user_tz":-600,"elapsed":971,"user":{"displayName":"Santosh Purja Pun","photoUrl":"https://lh3.googleusercontent.com/-lSFl4QnIVIk/AAAAAAAAAAI/AAAAAAAAAIY/zqCf6YZz0-4/s64/photo.jpg","userId":"11631572469968879053"}}},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","fig, ax = plt.subplots()\n","im = ax.imshow(cm, interpolation = \"nearest\", cmap = plt.cm.Blues)\n","\n","ax.set(xticks=np.arange(cm.shape[0]),\n","       yticks=np.arange(cm.shape[0]),\n","       title = \"Confusion Matrix\",\n","       ylabel = \"True label\",\n","       xlabel = \"Predicted Label\",\n","       xticklabels = classLabels,\n","       yticklabels = classLabels\n","      )\n","\n","for i in range(2):\n","  for j in range(2):\n","    ax.text(i, j, cm[j, i],\n","           color=\"white\" if i==j else \"black\")\n","\n","plt.show()"],"execution_count":114,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAATIAAAEWCAYAAADl+xvlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nn0bJpNScAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"bBM_oCwg_lSd","colab_type":"text"},"source":["Now, it is much more easier to intepret. As the name suggested, a confusion matrix describes the performance of a model by tabulating the true label or class against the predicted label or class and shows the number of times the model was confused and predicted wrong class. In this case, the number of times our model has correctly identified \"Malignant\" is 66 and that of \"Benign\" is 101. However in 2 cases our model has predicted \"benign\" when the corresponding true class was \"Malignant\". Similarly, for 2 of the examples with ground-truth class as \"benign\", our model has predicted \"Malignant\".\n","\n","Let's assume that the examples with class \"malignant\" as positive class and \"benign\" as negative class. Then, the number of times our model has correctly identified \"malignant\" are called **True Positives** and for \"Benign\" the number of correctly identified examples are called **True Negatives**. Likewise, the number of instances where our model has incorrectly identified \"Malignant\" as \"Benign\" are called **False Negative**. Similarly the number of instances where our model predicted \"Malignant\" when the actual class was \"Benign\" are called **False Positive**.\n","\n","Hence, we have the following numbers:\n","\n","True Positives (TP) = 66\n","\n","True Negatives (TN) = 101\n","\n","False Positives (FP) = 2\n","\n","False Negatives (FN) = 2\n","\n","On the basis of these numbers, we can calculate a bunch of other meaningful statistics. Some of them are:\n","\n","1) Accuracy (overall accuracy of our model)  = $\\frac{(TP + TN)}{(P + N)}$\n","= $\\frac{66 + 101}{171}$ = 0.9766 \n","\n","2) Misclassification Rate (How often our model is wrong?) = $\\frac{(FP + FN)}{(P + N)}$\n","= $\\frac{2 + 2}{171}$ = 0.0233 = 1-accuracy\n","\n","3) True Positive Rate (also called as sensitivity or recall), TPP (Correctly identified) = $\\frac{TP}{TP + FN}$\n","= $\\frac{66}{68}$ = 0.9705 = 1 - FNR \n","\n","4) True Negative Rate (also called specificity, selectivity), TNR, (correctly rejected) = $\\frac{TN}{TN + FP}$\n","= $\\frac{101}{103}$ = 0.9805 = 1 - FPR\n","\n","5) Positive Predictive value (PPV) or precision = $\\frac{TP}{TP + FP}$\n","= $\\frac{66}{68}$ = 0.9705\n","\n","6) Negative Predicted value = $\\frac{TN}{TN + FN}$\n","= $\\frac{101}{103}$ = 0.9805 \n","\n","7) False Negative Rate / miss rate (incorrectly rejected) = $\\frac{FN}{FN + TP}$\n","= $\\frac{2}{68}$ = 0.0294 \n","\n","8) False Positive Rate / fall-out (incorrectly identified) = $\\frac{FP}{TN + FP}$\n","= $\\frac{2}{103}$ = 0.0194 "]},{"cell_type":"markdown","metadata":{"id":"japPynbHMBuN","colab_type":"text"},"source":["##Next\n","The confusion matrix itself is simple, however it might take some time to get used to with the various statistical measures, of the performance of a classifier. The most important take-away of this tutorial, if I had to say, would be the way confusion matrix enables us to describe the performance of the model and at the same time, helps us to calculate various other performance measures, that might be meaningful while evaluating the perdictive performance of a classifier."]}]}